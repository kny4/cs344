{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e4fdf1",
   "metadata": {},
   "source": [
    "# Dynamic Quantization Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d890cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules used here in this recipe\n",
    "import torch\n",
    "import torch.quantization\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e09491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a very, very simple LSTM for demonstration purposes\n",
    "# in this case, we are wrapping nn.LSTM, one layer, no pre or post processing\n",
    "# inspired by\n",
    "# https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html, by Robert Guthrie\n",
    "# and https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html\n",
    "class lstm_for_demonstration(nn.Module):\n",
    "  \"\"\"Elementary Long Short Term Memory style model which simply wraps nn.LSTM\n",
    "     Not to be used for anything other than demonstration.\n",
    "  \"\"\"\n",
    "  def __init__(self,in_dim,out_dim,depth):\n",
    "     super(lstm_for_demonstration,self).__init__()\n",
    "     self.lstm = nn.LSTM(in_dim,out_dim,depth)\n",
    "\n",
    "  def forward(self,inputs,hidden):\n",
    "     out,hidden = self.lstm(inputs,hidden)\n",
    "     return out, hidden\n",
    "\n",
    "\n",
    "torch.manual_seed(29592)  # set the seed for reproducibility\n",
    "\n",
    "#shape parameters\n",
    "model_dimension=8\n",
    "sequence_length=20\n",
    "batch_size=1\n",
    "lstm_depth=1\n",
    "\n",
    "# random data for input\n",
    "inputs = torch.randn(sequence_length,batch_size,model_dimension)\n",
    "# hidden is actually is a tuple of the initial hidden state and the initial cell state\n",
    "hidden = (torch.randn(lstm_depth,batch_size,model_dimension), torch.randn(lstm_depth,batch_size,model_dimension))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69721696",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0024b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the floating point version of this module:\n",
      "lstm_for_demonstration(\n",
      "  (lstm): LSTM(8, 8)\n",
      ")\n",
      "\n",
      "and now the quantized version:\n",
      "lstm_for_demonstration(\n",
      "  (lstm): DynamicQuantizedLSTM(8, 8)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    " # here is our floating point instance\n",
    "float_lstm = lstm_for_demonstration(model_dimension, model_dimension,lstm_depth)\n",
    "\n",
    "# this is the call that does the work\n",
    "quantized_lstm = torch.quantization.quantize_dynamic(\n",
    "    float_lstm, {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# show the changes that were made\n",
    "print('Here is the floating point version of this module:')\n",
    "print(float_lstm)\n",
    "print('')\n",
    "print('and now the quantized version:')\n",
    "print(quantized_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72767aa9",
   "metadata": {},
   "source": [
    "### Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4074aa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  fp32  \t Size (KB): 3.743\n",
      "model:  int8  \t Size (KB): 2.719\n",
      "1.38 times smaller\n"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size=os.path.getsize(\"temp.p\")\n",
    "    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n",
    "    os.remove('temp.p')\n",
    "    return size\n",
    "\n",
    "# compare the sizes\n",
    "f=print_size_of_model(float_lstm,\"fp32\")\n",
    "q=print_size_of_model(quantized_lstm,\"int8\")\n",
    "print(\"{0:.2f} times smaller\".format(f/q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b0074b",
   "metadata": {},
   "source": [
    "### Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11704908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Floating point FP32\n",
      "478 µs ± 4.85 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "Quantized INT8\n",
      "296 µs ± 2.07 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# compare the performance\n",
    "print(\"Floating point FP32\")\n",
    "%timeit float_lstm.forward(inputs, hidden)\n",
    "\n",
    "print(\"Quantized INT8\")\n",
    "%timeit quantized_lstm.forward(inputs,hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55060e1e",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2bb4c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean absolute value of output tensor values in the FP32 model is 0.12887 \n",
      "mean absolute value of output tensor values in the INT8 model is 0.12912\n",
      "mean absolute value of the difference between the output tensors is 0.00156 or 1.21 percent\n"
     ]
    }
   ],
   "source": [
    "# run the float model\n",
    "out1, hidden1 = float_lstm(inputs, hidden)\n",
    "mag1 = torch.mean(abs(out1)).item()\n",
    "print('mean absolute value of output tensor values in the FP32 model is {0:.5f} '.format(mag1))\n",
    "\n",
    "# run the quantized model\n",
    "out2, hidden2 = quantized_lstm(inputs, hidden)\n",
    "mag2 = torch.mean(abs(out2)).item()\n",
    "print('mean absolute value of output tensor values in the INT8 model is {0:.5f}'.format(mag2))\n",
    "\n",
    "# compare them\n",
    "mag3 = torch.mean(abs(out1-out2)).item()\n",
    "print('mean absolute value of the difference between the output tensors is {0:.5f} or {1:.2f} percent'.format(mag3,mag3/mag1*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe248c",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9a632",
   "metadata": {},
   "source": [
    "The first tutorial I did was \"Dynamic Quantization\" which was one of the PyTorch Recipes. From what I can understand, this process is good for reducing the size of model weights and speed up execution. Starting with a minimal LSTM network, the model is then quantized as a new model. And voila, the new model stores about 75% less data and runs faster becasue of less parameter data to organize. Because the network was randomly initialized, there wasn't good accuracy that the tutorial could give, but the output tensors were similar to the original output tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70372aef",
   "metadata": {},
   "source": [
    "# Defining a Neural Network in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50227ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d662bd",
   "metadata": {},
   "source": [
    "### Define and Initialize Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174b1232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      # First 2D convolutional layer, taking in 1 input channel (image),\n",
    "      # outputting 32 convolutional features, with a square kernel size of 3\n",
    "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "      # Second 2D convolutional layer, taking in the 32 input layers,\n",
    "      # outputting 64 convolutional features, with a square kernel size of 3\n",
    "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "\n",
    "      # Designed to ensure that adjacent pixels are either all 0s or all active\n",
    "      # with an input probability\n",
    "      self.dropout1 = nn.Dropout2d(0.25)\n",
    "      self.dropout2 = nn.Dropout2d(0.5)\n",
    "\n",
    "      # First fully connected layer\n",
    "      self.fc1 = nn.Linear(9216, 128)\n",
    "      # Second fully connected layer that outputs our 10 labels\n",
    "      self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "my_nn = Net()\n",
    "print(my_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928faa60",
   "metadata": {},
   "source": [
    "### Specify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3bd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "      self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "      self.dropout1 = nn.Dropout2d(0.25)\n",
    "      self.dropout2 = nn.Dropout2d(0.5)\n",
    "      self.fc1 = nn.Linear(9216, 128)\n",
    "      self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "      # Pass data through conv1\n",
    "      x = self.conv1(x)\n",
    "      # Use the rectified-linear activation function over x\n",
    "      x = F.relu(x)\n",
    "\n",
    "      x = self.conv2(x)\n",
    "      x = F.relu(x)\n",
    "\n",
    "      # Run max pooling over x\n",
    "      x = F.max_pool2d(x, 2)\n",
    "      # Pass data through dropout1\n",
    "      x = self.dropout1(x)\n",
    "      # Flatten x with start_dim=1\n",
    "      x = torch.flatten(x, 1)\n",
    "      # Pass data through fc1\n",
    "      x = self.fc1(x)\n",
    "      x = F.relu(x)\n",
    "      x = self.dropout2(x)\n",
    "      x = self.fc2(x)\n",
    "\n",
    "      # Apply softmax to x\n",
    "      output = F.log_softmax(x, dim=1)\n",
    "      return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8affe61c",
   "metadata": {},
   "source": [
    "### Pass Data Through Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93be8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3651, -2.3155, -2.3088, -2.2563, -2.2478, -2.3382, -2.3185, -2.2821,\n",
      "         -2.2442, -2.3584]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Equates to one random 28x28 image\n",
    "random_data = torch.rand((1, 1, 28, 28))\n",
    "\n",
    "my_nn = Net()\n",
    "result = my_nn(random_data)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2a805",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d6627f",
   "metadata": {},
   "source": [
    "This was the second PyTorch recipe tutorial I did. While simple, I learned how PyTorch provides modules and classes to create and train neural networks. The network built recognizes images using convolution. The model was defined to take 1 input image and output 10 labels representing numbers 0 to 9 following the MNIST algorithm. The PyTorch model needs to have the forward function defined, whcih dictates how the data is passed into the computation graph. The forward function is compatible with any tensor operations. To test the model, the recipe passed random data through it, resulting in tensors that equate to the prediciton of the label that the random tensow is associated to."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
