{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a5349b1",
   "metadata": {},
   "source": [
    "# Building a Song Recommender  \n",
    "by Braden Weber (blw22) and Kelsey Yen (kny4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94f5e68",
   "metadata": {},
   "source": [
    "## Goal  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c7875",
   "metadata": {},
   "source": [
    "The goal of our project is to create a song recommender using the Spotify Million Playlist Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c33a4",
   "metadata": {},
   "source": [
    "## The Dataset  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f16a3a",
   "metadata": {},
   "source": [
    "The dataset we used is from the [Spotify Million Playlist Dataset Challenge](https://research.atspotify.com/the-million-playlist-dataset-remastered/). The data comes from sampling random existing Spotify playlists made by real users for Spotify's AI research (much of which focuses on recommendation systems).  \n",
    "Each playlist is a dictionary that includes data. The data we used was from the field \"tracks\" which includes the following data:\n",
    "* **track_name** - the name of the track\n",
    "* **track_uri** - the Spotify URI of the track\n",
    "* **album_name** - the name of the track's album\n",
    "* **album_uri** - the Spotify URI of the album\n",
    "* **artist_name** - the name of the track's primary artist\n",
    "* **artist_uri** - the Spotify URI of track's primary artist\n",
    "* **duration_ms** - the duration of the track in milliseconds\n",
    "* **pos** - the position of the track in the playlist (zero-based)  \n",
    "\n",
    "Unlike other datasets we explored, the dataset does not include song attributes that can be compared to one another, things like tempo, genre, or danceability (although attributes are available using Spotify Web API). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe4211",
   "metadata": {},
   "source": [
    "After unzipping the dataset, the data is put into a dataframe using a `for loop` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c330b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f04927",
   "metadata": {},
   "source": [
    "We run through every playlist and delete the ones with less than 30 songs then we shorten every playlist longer than 30 songs to only 30 songs. This makes every playlist the same size so that it works well with tensors.\n",
    "Then we yank out the last ten songs in each playlist as a possible target song for the model to guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for yeeting 10 songs into training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40946b4",
   "metadata": {},
   "source": [
    "The model needs to have each unique track labelled with a unique index in the set tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612499b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# for loops for song indeces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492add3f",
   "metadata": {},
   "source": [
    "Now each song can be identified with a unique id. We then go back through every playlist and replace it wiht its id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc7835d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# code for playlists, all playlists are just id numbers\n",
    "# make training playlists and playlist_list into tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831623c",
   "metadata": {},
   "source": [
    "Training shape is the number of playlists  \n",
    "Playlists shape is the number for every playlist, there are 20 songs tensor[4..., 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f590a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# tensor shape code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389d4478",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d7e45",
   "metadata": {},
   "source": [
    "Following sequence modelling done in homeworks 6 and 12. To set up the embedding of each song, we used the number of unique songs, the embedding dimension (50, hopefully enough to learn to associate different song attributes to all songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77184f4a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# unique songs number\n",
    "# embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595337a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# num parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c43f46f",
   "metadata": {},
   "source": [
    "Insert tensor of playlists into embedder to create tensor that has the embeddings for each song in the playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c985b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for playlist embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c36b9",
   "metadata": {},
   "source": [
    "MLP setup. There's two (not three). Each corresponds to the new parameters added to it. Input is the embedding dimension, out put is also the embedding dimension. Mean is a tensor of length 50 and is the average of the rows for each embedding for the songs (an average of all the songs). Variance finds the difference ebtween all the songs. The final thing it inputs is the actual song to be recommended. The model then has two inputs.  \n",
    "The head mlp has an extra layer to output the number of unique songs. We keep the input to 50 because the kernel keeps dying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1929e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for mean, variance, head "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170cb9a",
   "metadata": {},
   "source": [
    "Code for model setup based on the target with a single song embedding. Returns the output of the last mlp which is the large array that is softmaxed for probablities. Insert pretty picture here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce929b",
   "metadata": {},
   "source": [
    "Training the model: It goes through every playlist in the list \"playlist\" (it enumerates), taking the playlist and runs through the model, outputting a tensor with the probability of reommendation of each unique song. (big-ass array)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d4b40",
   "metadata": {},
   "source": [
    "Cross-entropy takes two argument: the big-ass array of probbailities of each unique song and the index of the answer (which is the song we want it to recommend because it's in the original playlist set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3efd3f",
   "metadata": {},
   "source": [
    "Goes backward down the gradient to update each parameter in the model from the gradient. IMPORTANT: Zero the gradient every time the loss is used to back propogate to create the gradients. This saves memory space and keeps the kernel alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9696a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for setting up training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc52c5e",
   "metadata": {},
   "source": [
    "learning rate: how fast the weights change as it goes backwards along the gradient in the mlp\n",
    "files: changes how many playlists are loaded in\n",
    "training set: how many traning sets the model runs through\n",
    "rounds: how many times the whole process is repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9adea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for changing parameters maybe here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73afa65",
   "metadata": {},
   "source": [
    "How we do epochs/rounds: For loop that runs every playlist through the model and back propogates the loss. For each time is runs through the epoch, there is alaso a loop for it to run throguh the number of training sets it wants. Nested in the loops is the call to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop for epochs/rounds \n",
    "# outputs training set number based on epoch round"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec3501",
   "metadata": {},
   "source": [
    "show_recommendations: shows the top 15 songs that the model recommends. It takes in the index of the plalist (index 25 is a country playlist). It shows what each training set had as it's training target and then the actual song it recommended with the confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b3445a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# code for show_recommendations with top 15 songs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbe221",
   "metadata": {},
   "source": [
    "To validate the model, we analyzed the number of country songs were recommended (generally most distinguishable genre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for get_playlist(25) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205528c1",
   "metadata": {},
   "source": [
    "The validation is to show that the model can at least recognize genres of songs and recommend a song within that genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea83fcb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# table for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1530fe",
   "metadata": {},
   "source": [
    "## Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630d2d7",
   "metadata": {},
   "source": [
    "Upping training set, modularizing model to just change parameters, going from concatenating embeddings to using a sequential model\n",
    "\n",
    "In terms of optimizing parameters, blah blah blah smart smart\n",
    "\n",
    "Removing one of the mlps since target is not added into the training portion. Results will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f7ea3",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334160a1",
   "metadata": {},
   "source": [
    "Cross-entropy loss function\n",
    "Loss.backward() carries the loss through the whole model\n",
    "\n",
    "Counting country songs in output? Does this count?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb2797",
   "metadata": {},
   "source": [
    "## Alternative Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddf72fb",
   "metadata": {},
   "source": [
    "Many different ways to set up this sequential model\n",
    "Earlier idea of concatenating mean, variance, and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72be1c",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d2d5f",
   "metadata": {},
   "source": [
    "Needs lots of data and subsequent time to train on (some recommenders we saw online took 3-4 days to train)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
